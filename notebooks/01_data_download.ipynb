{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a3afbe",
   "metadata": {},
   "source": [
    "# Data Download and Preparation\n",
    "\n",
    "This notebook downloads Indian stock market data and prepares it for volatility modeling.\n",
    "\n",
    "## Key Features:\n",
    "- NSE/BSE stock data download\n",
    "- VIX data integration\n",
    "- FII/DII flow data\n",
    "- Options chain processing\n",
    "- Data quality checks\n",
    "- Initial volatility calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from src.config.settings import get_config\n",
    "from src.data.nse_data import NSEDataSource\n",
    "from src.data.vix_data import VIXDataSource\n",
    "from src.data.options_data import OptionsDataSource\n",
    "from src.utils.logging import get_logger\n",
    "from src.features.volatility_estimators import VolatilityEstimators\n",
    "\n",
    "# Initialize configuration and logger\n",
    "config = get_config()\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "print(\"Project modules imported successfully\")\n",
    "print(f\"Data directory: {config.data.raw_data_path}\")\n",
    "print(f\"Processing directory: {config.data.processed_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0032435",
   "metadata": {},
   "source": [
    "## 1. Download NSE Stock Data\n",
    "\n",
    "Download historical data for major Indian stocks and indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60423945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NSE data source\n",
    "nse_source = NSEDataSource()\n",
    "\n",
    "# Define symbols to download\n",
    "symbols = [\n",
    "    'NIFTY50.NS',    # Nifty 50 Index\n",
    "    'NIFTYBANK.NS',  # Bank Nifty\n",
    "    'RELIANCE.NS',   # Reliance Industries\n",
    "    'TCS.NS',        # TCS\n",
    "    'INFY.NS',       # Infosys\n",
    "    'HDFC.NS',       # HDFC\n",
    "    'ICICIBANK.NS',  # ICICI Bank\n",
    "    'SBIN.NS',       # State Bank of India\n",
    "    'ITC.NS',        # ITC\n",
    "    'LT.NS'          # Larsen & Toubro\n",
    "]\n",
    "\n",
    "# Date range for data download\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365*3)  # 3 years of data\n",
    "\n",
    "print(f\"Downloading data from {start_date.date()} to {end_date.date()}\")\n",
    "print(f\"Symbols: {symbols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e93ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stock data\n",
    "stock_data = {}\n",
    "failed_downloads = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        print(f\"Downloading {symbol}...\")\n",
    "        data = nse_source.get_historical_data(\n",
    "            symbol=symbol,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date\n",
    "        )\n",
    "        \n",
    "        if not data.empty:\n",
    "            stock_data[symbol] = data\n",
    "            print(f\"  ✓ Downloaded {len(data)} records for {symbol}\")\n",
    "        else:\n",
    "            print(f\"  ✗ No data found for {symbol}\")\n",
    "            failed_downloads.append(symbol)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed to download {symbol}: {e}\")\n",
    "        failed_downloads.append(symbol)\n",
    "\n",
    "print(f\"\\nSuccessfully downloaded data for {len(stock_data)} symbols\")\n",
    "if failed_downloads:\n",
    "    print(f\"Failed downloads: {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "if stock_data:\n",
    "    sample_symbol = list(stock_data.keys())[0]\n",
    "    sample_data = stock_data[sample_symbol]\n",
    "    \n",
    "    print(f\"Sample data for {sample_symbol}:\")\n",
    "    print(f\"Shape: {sample_data.shape}\")\n",
    "    print(f\"Date range: {sample_data.index[0]} to {sample_data.index[-1]}\")\n",
    "    print(f\"Columns: {list(sample_data.columns)}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(sample_data.head())\n",
    "    \n",
    "    print(\"\\nLast 5 rows:\")\n",
    "    display(sample_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd1380",
   "metadata": {},
   "source": [
    "## 2. Download VIX Data\n",
    "\n",
    "Download India VIX (volatility index) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ce5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VIX data source\n",
    "vix_source = VIXDataSource()\n",
    "\n",
    "try:\n",
    "    print(\"Downloading India VIX data...\")\n",
    "    vix_data = vix_source.get_vix_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "    \n",
    "    if not vix_data.empty:\n",
    "        print(f\"✓ Downloaded {len(vix_data)} VIX records\")\n",
    "        print(f\"VIX date range: {vix_data.index[0]} to {vix_data.index[-1]}\")\n",
    "        print(f\"VIX columns: {list(vix_data.columns)}\")\n",
    "        display(vix_data.head())\n",
    "    else:\n",
    "        print(\"✗ No VIX data found\")\n",
    "        vix_data = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to download VIX data: {e}\")\n",
    "    vix_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe34545",
   "metadata": {},
   "source": [
    "## 3. Process Options Chain Data\n",
    "\n",
    "Process options chain data for put-call ratio and implied volatility analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for options chain file\n",
    "options_file = os.path.join(project_root, 'option-chain-ED-NIFTY-02-Sep-2025.csv')\n",
    "\n",
    "if os.path.exists(options_file):\n",
    "    print(f\"Found options chain file: {options_file}\")\n",
    "    \n",
    "    # Load options data\n",
    "    options_raw = pd.read_csv(options_file)\n",
    "    print(f\"Options data shape: {options_raw.shape}\")\n",
    "    print(f\"Options columns: {list(options_raw.columns)}\")\n",
    "    display(options_raw.head())\n",
    "    \n",
    "else:\n",
    "    print(f\"Options chain file not found at: {options_file}\")\n",
    "    options_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72919d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process options data if available\n",
    "options_processed = None\n",
    "\n",
    "if options_raw is not None:\n",
    "    try:\n",
    "        options_source = OptionsDataSource()\n",
    "        \n",
    "        # Process the options chain data\n",
    "        print(\"Processing options chain data...\")\n",
    "        \n",
    "        # Basic processing - calculate put-call ratios, implied volatility, etc.\n",
    "        options_processed = options_source.process_options_chain(options_raw)\n",
    "        \n",
    "        if options_processed is not None:\n",
    "            print(f\"✓ Processed options data shape: {options_processed.shape}\")\n",
    "            print(f\"Processed columns: {list(options_processed.columns)}\")\n",
    "            display(options_processed.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to process options data: {e}\")\n",
    "        options_processed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e589f2",
   "metadata": {},
   "source": [
    "## 4. Data Quality Checks\n",
    "\n",
    "Perform comprehensive data quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ca9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary\n",
    "print(\"=== DATA QUALITY SUMMARY ===\")\n",
    "print(f\"Total symbols downloaded: {len(stock_data)}\")\n",
    "\n",
    "for symbol, data in stock_data.items():\n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Records: {len(data)}\")\n",
    "    print(f\"  Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "    print(f\"  Missing values: {data.isnull().sum().sum()}\")\n",
    "    print(f\"  Zero volumes: {(data['Volume'] == 0).sum() if 'Volume' in data.columns else 'N/A'}\")\n",
    "    \n",
    "    # Check for outliers in price movements\n",
    "    if 'Close' in data.columns:\n",
    "        returns = data['Close'].pct_change()\n",
    "        outliers = np.abs(returns) > 0.15  # >15% daily moves\n",
    "        print(f\"  Large moves (>15%): {outliers.sum()}\")\n",
    "        \n",
    "        if outliers.sum() > 0:\n",
    "            print(f\"  Extreme move dates: {data.index[outliers].tolist()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data availability\n",
    "if stock_data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Price movements for major indices\n",
    "    ax1 = axes[0, 0]\n",
    "    for symbol in ['NIFTY50.NS', 'NIFTYBANK.NS']:\n",
    "        if symbol in stock_data and 'Close' in stock_data[symbol].columns:\n",
    "            data = stock_data[symbol]['Close']\n",
    "            normalized = data / data.iloc[0] * 100\n",
    "            ax1.plot(normalized.index, normalized.values, label=symbol, linewidth=1.5)\n",
    "    \n",
    "    ax1.set_title('Normalized Index Performance')\n",
    "    ax1.set_ylabel('Normalized Price (Base=100)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Volume patterns\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'NIFTY50.NS' in stock_data and 'Volume' in stock_data['NIFTY50.NS'].columns:\n",
    "        volume_data = stock_data['NIFTY50.NS']['Volume']\n",
    "        ax2.plot(volume_data.index, volume_data.values, alpha=0.7)\n",
    "        ax2.set_title('Trading Volume (NIFTY50)')\n",
    "        ax2.set_ylabel('Volume')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: VIX if available\n",
    "    ax3 = axes[1, 0]\n",
    "    if vix_data is not None and not vix_data.empty:\n",
    "        ax3.plot(vix_data.index, vix_data.iloc[:, 0], color='red', linewidth=2)\n",
    "        ax3.set_title('India VIX')\n",
    "        ax3.set_ylabel('VIX Level')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'VIX Data\\nNot Available', \n",
    "                ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "        ax3.set_title('India VIX (Not Available)')\n",
    "    \n",
    "    # Plot 4: Data availability heatmap\n",
    "    ax4 = axes[1, 1]\n",
    "    if stock_data:\n",
    "        # Create availability matrix\n",
    "        all_dates = pd.date_range(\n",
    "            start=min(data.index.min() for data in stock_data.values()),\n",
    "            end=max(data.index.max() for data in stock_data.values()),\n",
    "            freq='D'\n",
    "        )\n",
    "        \n",
    "        availability = pd.DataFrame(index=all_dates, columns=list(stock_data.keys()))\n",
    "        \n",
    "        for symbol, data in stock_data.items():\n",
    "            availability.loc[data.index, symbol] = 1\n",
    "        \n",
    "        availability = availability.fillna(0)\n",
    "        \n",
    "        # Sample for visualization (every 7th day)\n",
    "        sample_availability = availability.iloc[::7]\n",
    "        \n",
    "        im = ax4.imshow(sample_availability.T, aspect='auto', cmap='RdYlGn', alpha=0.8)\n",
    "        ax4.set_title('Data Availability')\n",
    "        ax4.set_ylabel('Symbols')\n",
    "        ax4.set_yticks(range(len(stock_data)))\n",
    "        ax4.set_yticklabels([s.replace('.NS', '') for s in stock_data.keys()], fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Data quality visualization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f5ec0",
   "metadata": {},
   "source": [
    "## 5. Calculate Initial Volatility Estimates\n",
    "\n",
    "Calculate various volatility estimators for the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f28900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize volatility estimators\n",
    "vol_estimator = VolatilityEstimators()\n",
    "\n",
    "# Calculate volatility estimates for NIFTY50\n",
    "if 'NIFTY50.NS' in stock_data:\n",
    "    nifty_data = stock_data['NIFTY50.NS']\n",
    "    \n",
    "    print(\"Calculating volatility estimates for NIFTY50...\")\n",
    "    \n",
    "    # Simple returns volatility\n",
    "    returns = nifty_data['Close'].pct_change().dropna()\n",
    "    simple_vol = vol_estimator.simple_volatility(returns, window=30)\n",
    "    \n",
    "    print(f\"✓ Simple volatility calculated: {len(simple_vol)} observations\")\n",
    "    \n",
    "    # High-frequency estimators (if OHLC data available)\n",
    "    required_cols = ['Open', 'High', 'Low', 'Close']\n",
    "    if all(col in nifty_data.columns for col in required_cols):\n",
    "        \n",
    "        # Parkinson estimator\n",
    "        parkinson_vol = vol_estimator.parkinson_estimator(\n",
    "            nifty_data['High'], nifty_data['Low']\n",
    "        )\n",
    "        \n",
    "        # Garman-Klass estimator\n",
    "        gk_vol = vol_estimator.garman_klass_estimator(\n",
    "            nifty_data['Open'], nifty_data['High'], \n",
    "            nifty_data['Low'], nifty_data['Close']\n",
    "        )\n",
    "        \n",
    "        # Rogers-Satchell estimator\n",
    "        rs_vol = vol_estimator.rogers_satchell_estimator(\n",
    "            nifty_data['Open'], nifty_data['High'], \n",
    "            nifty_data['Low'], nifty_data['Close']\n",
    "        )\n",
    "        \n",
    "        # Yang-Zhang estimator\n",
    "        yz_vol = vol_estimator.yang_zhang_estimator(\n",
    "            nifty_data['Open'], nifty_data['High'], \n",
    "            nifty_data['Low'], nifty_data['Close']\n",
    "        )\n",
    "        \n",
    "        print(\"✓ All volatility estimators calculated\")\n",
    "        \n",
    "        # Combine volatility estimates\n",
    "        volatility_df = pd.DataFrame({\n",
    "            'Simple': simple_vol,\n",
    "            'Parkinson': parkinson_vol,\n",
    "            'Garman_Klass': gk_vol,\n",
    "            'Rogers_Satchell': rs_vol,\n",
    "            'Yang_Zhang': yz_vol\n",
    "        })\n",
    "        \n",
    "        print(f\"Volatility estimates shape: {volatility_df.shape}\")\n",
    "        display(volatility_df.head())\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠ OHLC data not complete, using simple volatility only\")\n",
    "        volatility_df = pd.DataFrame({'Simple': simple_vol})\n",
    "\n",
    "else:\n",
    "    print(\"⚠ NIFTY50 data not available for volatility calculation\")\n",
    "    volatility_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01445beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot volatility estimates comparison\n",
    "if volatility_df is not None and len(volatility_df.columns) > 1:\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Time series of all volatility estimates\n",
    "    ax1 = axes[0, 0]\n",
    "    for col in volatility_df.columns:\n",
    "        ax1.plot(volatility_df.index, volatility_df[col] * 100, \n",
    "                label=col, linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    ax1.set_title('Volatility Estimates Comparison (%)')\n",
    "    ax1.set_ylabel('Annualized Volatility (%)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Correlation heatmap\n",
    "    ax2 = axes[0, 1]\n",
    "    corr_matrix = volatility_df.corr()\n",
    "    im = ax2.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    ax2.set_title('Volatility Estimator Correlations')\n",
    "    ax2.set_xticks(range(len(corr_matrix.columns)))\n",
    "    ax2.set_yticks(range(len(corr_matrix.columns)))\n",
    "    ax2.set_xticklabels(corr_matrix.columns, rotation=45)\n",
    "    ax2.set_yticklabels(corr_matrix.columns)\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i in range(len(corr_matrix)):\n",
    "        for j in range(len(corr_matrix)):\n",
    "            ax2.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                    ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    plt.colorbar(im, ax=ax2)\n",
    "    \n",
    "    # Plot 3: Distribution comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    volatility_df.plot(kind='hist', bins=30, alpha=0.7, ax=ax3)\n",
    "    ax3.set_title('Volatility Distribution')\n",
    "    ax3.set_xlabel('Volatility')\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot 4: Summary statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    summary_stats = volatility_df.describe()\n",
    "    \n",
    "    # Create summary table\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    table_data = summary_stats.round(4)\n",
    "    table = ax4.table(cellText=table_data.values,\n",
    "                     rowLabels=table_data.index,\n",
    "                     colLabels=table_data.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.5)\n",
    "    ax4.set_title('Summary Statistics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif volatility_df is not None:\n",
    "    # Simple plot for single volatility estimate\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(volatility_df.index, volatility_df.iloc[:, 0] * 100, linewidth=2)\n",
    "    plt.title('NIFTY50 Volatility (30-day rolling)')\n",
    "    plt.ylabel('Annualized Volatility (%)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Volatility analysis completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864718c2",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data\n",
    "\n",
    "Save all processed data for use in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories if they don't exist\n",
    "raw_data_dir = os.path.join(project_root, 'data', 'raw')\n",
    "processed_data_dir = os.path.join(project_root, 'data', 'processed')\n",
    "\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Data directories:\")\n",
    "print(f\"  Raw: {raw_data_dir}\")\n",
    "print(f\"  Processed: {processed_data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stock data\n",
    "saved_files = []\n",
    "\n",
    "for symbol, data in stock_data.items():\n",
    "    filename = f\"{symbol.replace('.NS', '')}_stock_data.csv\"\n",
    "    filepath = os.path.join(raw_data_dir, filename)\n",
    "    \n",
    "    data.to_csv(filepath)\n",
    "    saved_files.append(filepath)\n",
    "    print(f\"✓ Saved {symbol} data to {filename}\")\n",
    "\n",
    "# Save VIX data\n",
    "if vix_data is not None and not vix_data.empty:\n",
    "    vix_filepath = os.path.join(raw_data_dir, 'india_vix_data.csv')\n",
    "    vix_data.to_csv(vix_filepath)\n",
    "    saved_files.append(vix_filepath)\n",
    "    print(f\"✓ Saved VIX data to india_vix_data.csv\")\n",
    "\n",
    "# Save options data\n",
    "if options_processed is not None:\n",
    "    options_filepath = os.path.join(processed_data_dir, 'options_processed.csv')\n",
    "    options_processed.to_csv(options_filepath)\n",
    "    saved_files.append(options_filepath)\n",
    "    print(f\"✓ Saved processed options data to options_processed.csv\")\n",
    "\n",
    "# Save volatility estimates\n",
    "if volatility_df is not None:\n",
    "    vol_filepath = os.path.join(processed_data_dir, 'nifty50_volatility_estimates.csv')\n",
    "    volatility_df.to_csv(vol_filepath)\n",
    "    saved_files.append(vol_filepath)\n",
    "    print(f\"✓ Saved volatility estimates to nifty50_volatility_estimates.csv\")\n",
    "\n",
    "print(f\"\\nTotal files saved: {len(saved_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3600e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data summary report\n",
    "summary_report = {\n",
    "    'download_timestamp': datetime.now().isoformat(),\n",
    "    'data_period': {\n",
    "        'start_date': start_date.isoformat(),\n",
    "        'end_date': end_date.isoformat()\n",
    "    },\n",
    "    'symbols_downloaded': list(stock_data.keys()),\n",
    "    'failed_downloads': failed_downloads,\n",
    "    'vix_available': vix_data is not None and not vix_data.empty,\n",
    "    'options_available': options_processed is not None,\n",
    "    'volatility_estimates_available': volatility_df is not None,\n",
    "    'data_files': saved_files,\n",
    "    'data_quality': {\n",
    "        symbol: {\n",
    "            'records': len(data),\n",
    "            'missing_values': data.isnull().sum().sum(),\n",
    "            'date_range': [data.index[0].isoformat(), data.index[-1].isoformat()]\n",
    "        }\n",
    "        for symbol, data in stock_data.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary report\n",
    "import json\n",
    "summary_filepath = os.path.join(processed_data_dir, 'data_download_summary.json')\n",
    "with open(summary_filepath, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved data summary report to data_download_summary.json\")\n",
    "print(\"\\n=== DATA DOWNLOAD COMPLETED ===\")\n",
    "print(f\"Successfully downloaded and processed data for {len(stock_data)} symbols\")\n",
    "print(f\"All data saved to: {processed_data_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
